{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "3_20_group_classification_Xuân Tuyến.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.10"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "A7-T_kM0U8QQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "611efb3f-7591-4f74-d261-e628eaa0a331"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive\")\n",
        "\n",
        "import os\n",
        "os.chdir(\"/content/drive/My Drive/DL/Lesson13/thuchanh\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A1mEx_z52Giv"
      },
      "source": [
        "**Nội dung bài thực hành**\n",
        "\n",
        "Người học tiếp cận và giải quyết bài toán phân lớp văn bản sử dụng Deep Learning với kiến trúc LSTM. Sau khi thực hành, người học có khả năng:\n",
        "1. Sử dụng được các công cụ của sklearn cho bài toán phân lớp\n",
        "  \n",
        "\n",
        "*   Thao tác với dữ liệu\n",
        "*   Chuyển từ văn bản sang không gian vector\n",
        "\n",
        "\n",
        "2. Áp dụng được Deep Learning cho bài toán phân lớp\n",
        "\n",
        "\n",
        "*   Huấn luyện mô hình\n",
        "*   Đánh gía mô hình\n",
        "\n",
        "\n",
        "3. Cải tiến được mô hình phân lớp\n",
        "3. Thực hành được với bài toán thực tế"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ETXOaYxP3kMH"
      },
      "source": [
        "**Thao tác với dữ liệu**\n",
        "\n",
        "\n",
        "\n",
        "*   Bài thực hành sử dụng dữ liệu tiếng Anh\n",
        "*   Dữ liệu gồm 18.000 bài báo được tổ chức trong 20 lớp (classes/groups)\n",
        "*   Yêu cầu: xây dựng mô hình phân lớp các bài báo dựa trên mô hình LSTM\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aQwYcPExCseE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0d23c6da-6a11-44a9-e8b5-948ca5299c16"
      },
      "source": [
        "#Loading the data set - training data.\n",
        "from sklearn.datasets import fetch_20newsgroups\n",
        "twenty_train = fetch_20newsgroups(subset='train', shuffle=True)\n",
        "twenty_test = fetch_20newsgroups(subset='test', shuffle=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading 20news dataset. This may take a few minutes.\n",
            "Downloading dataset from https://ndownloader.figshare.com/files/5975967 (14 MB)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WlShGKtxfgFg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e7b5a809-cde9-4436-9227-d83e5b0efe3c"
      },
      "source": [
        "len(twenty_test.data)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "7532"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tf7UZnmO4Zad"
      },
      "source": [
        "**Quan sát dữ liệu huấn luyện**\n",
        "\n",
        "\n",
        "\n",
        "*   Số lượng dữ liệu huấn luyện\n",
        "*   Quan sát một số bản ghi đầu tiên\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "082psamT5sAB"
      },
      "source": [
        "\n",
        "\n",
        "*   Xem danh sách tên các lớp bằng câu lệnh dưới đây"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MW9sm30-ycmY",
        "outputId": "a76a9927-665d-46a7-80d8-ee99c043fdde"
      },
      "source": [
        "# YOUR CODE HERE\r\n",
        "print(\"Ten cac lop\", twenty_train.target_names)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Ten cac lop ['alt.atheism', 'comp.graphics', 'comp.os.ms-windows.misc', 'comp.sys.ibm.pc.hardware', 'comp.sys.mac.hardware', 'comp.windows.x', 'misc.forsale', 'rec.autos', 'rec.motorcycles', 'rec.sport.baseball', 'rec.sport.hockey', 'sci.crypt', 'sci.electronics', 'sci.med', 'sci.space', 'soc.religion.christian', 'talk.politics.guns', 'talk.politics.mideast', 'talk.politics.misc', 'talk.religion.misc']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9JA3KhUT6TJK"
      },
      "source": [
        "\n",
        "\n",
        "*   Nhãn của các lớp\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1gBJdUSP6KQl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "86fbede9-e5b9-41e2-8946-1a3bc3ec7961"
      },
      "source": [
        "# YOUR CODE HERE\r\n",
        "print(\"Nhan cac lop\", twenty_train.target)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Nhan cac lop [7 4 4 ... 3 1 8]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kOVjsTU-65GU"
      },
      "source": [
        "\n",
        "\n",
        "*  Hiển thị dòng đầu tiên của văn bản đầu tiên\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NVjOl_m3C_jV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2a310c06-5477-44c2-ba70-65e5403712e5"
      },
      "source": [
        "print(\"\\n\".join(twenty_train.data[0].split(\"\\n\")[:3])) #prints first line of the first data file"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "From: lerxst@wam.umd.edu (where's my thing)\n",
            "Subject: WHAT car is this!?\n",
            "Nntp-Posting-Host: rac3.wam.umd.edu\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8p0K_shM7D_i"
      },
      "source": [
        "#**Câu 1**: Tiền xử lý dữ liệu\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "odWmZfuk74b4"
      },
      "source": [
        "1.1: Lập trình hàm preprocessor để loại bỏ những ký tự thừa ra khỏi văn bản"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q0hejjBkDFLS",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "outputId": "92e54707-a8a7-4b2c-b587-cf583d607745"
      },
      "source": [
        "import re\n",
        "# Extracting features from text files\n",
        "# YOUR CODE HERE\n",
        "def clean_info(text):\n",
        "  # YOUR CODE HERE\n",
        "  text = \"\".join(text.split(\"\\n\")[1:])\n",
        "  return text\n",
        "def preprocessor(text):\n",
        "    \n",
        "    text = re.sub(r\"<[^>]>\", '', text)\n",
        "    text = re.sub(\"[\\W]+\", \" \", text.lower())\n",
        "\n",
        "    return text.lower().strip()\n",
        "\n",
        "def preprocess_whole_data(docs):\n",
        "  # YOUR CODE HERE\n",
        "  processed_text = [preprocessor(clean_info(data)) for data in docs.data]\n",
        "  return processed_text\n",
        "\n",
        "# YOUR CODE HERE\n",
        "preprocessor(clean_info(twenty_train.data[0]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'subject what car is this nntp posting host rac3 wam umd eduorganization university of maryland college parklines 15 i was wondering if anyone out there could enlighten me on this car i sawthe other day it was a 2 door sports car looked to be from the late 60s early 70s it was called a bricklin the doors were really small in addition the front bumper was separate from the rest of the body this is all i know if anyone can tellme a model name engine specs yearsof production where this car is made history or whatever info youhave on this funky looking car please e mail thanks il brought to you by your neighborhood lerxst'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qItdhpt4j2m8"
      },
      "source": [
        "1.2. Tiền xử lý cho cả tập train và test"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3sN63MeL-mgQ"
      },
      "source": [
        "# YOUR CODE HERE\n",
        "process_train_data = preprocess_whole_data(twenty_train)\n",
        "process_test_data = preprocess_whole_data(twenty_test)\n",
        "# YOUR CODE HERE"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ODnZ_bTQfKgS"
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.layers import LSTM\n",
        "from tensorflow.compat.v1.keras.layers import CuDNNLSTM # comment dong nay neu may ban khong ho tro CuDNN\n",
        "from tensorflow.keras.layers import Embedding\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Input, TimeDistributed, BatchNormalization\n",
        "from tensorflow.keras.layers import Activation, Dense, Dropout\n",
        "from tensorflow.keras.layers import Bidirectional\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras import backend as K\n",
        "\n",
        "\n",
        "\n",
        "# embedding\n",
        "word2vec_file = 'GoogleNews-vectors-negative300.bin'\n",
        "glove_file = 'glove.6B.300d.txt'\n",
        "fasttext_file = 'wiki-news-300d-1M.vec'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NJM8-qdFkMnC"
      },
      "source": [
        "1.3: Biến đổi từ về dạng token trong câu"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "keIWqNVPfDfG"
      },
      "source": [
        "# YOUR CODE HERE\n",
        "tokenizer = Tokenizer(num_words=5000)\n",
        "tokenizer.fit_on_texts(process_train_data)\n",
        "X_train = tokenizer.texts_to_sequences(process_train_data)\n",
        "X_test = tokenizer.texts_to_sequences(process_test_data)\n",
        "X_train = pad_sequences(X_train, maxlen=500)\n",
        "X_test = pad_sequences(X_test, maxlen=500)\n",
        "# YOUR CODE HERE"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tRpL4UWLfx6H"
      },
      "source": [
        "1.4: Biến đổi nhãn về dạng One-hot Vector"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rnPRm2nvfwM-"
      },
      "source": [
        "# YOUR CODE HERE\n",
        "train_one_hot = to_categorical(twenty_train.target.reshape(-1,1))\n",
        "test_one_hot = to_categorical(twenty_test.target.reshape(-1,1))\n",
        "\n",
        "# YOUR CODE HERE\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8NjXfsvr-YkH"
      },
      "source": [
        "# **Câu 2:** Xây dựng mô hình\n",
        "2.1. Thiết lập tham số"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L6SbSY7sgfiA"
      },
      "source": [
        "\n",
        "# YOUR CODE HERE\n",
        "max_len = 300\n",
        "num_words = 5000\n",
        "embedding_dim = 300\n",
        "dropout = 0.5\n",
        "hidden_dim = 750\n",
        "l2_reg = 1e-4\n",
        "batch_size = 160\n",
        "epochs = 15\n",
        "learning_rate = 1e-3\n",
        "lstm = CuDNNLSTM\n",
        "opt = 'adam'\n",
        "# YOUR CODE HERE"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T-t5zZN28Jy6"
      },
      "source": [
        "2.2. Biểu diễn văn bản bằng Word2vec, Glove, và Fasttext\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q-pvoTiYcd_P"
      },
      "source": [
        "from gensim.models import KeyedVectors\n",
        "from gensim.models.wrappers import FastText\n",
        "import numpy as np\n",
        "\n",
        "def get_embedded(wordvector):\n",
        "    # YOUR CODE HERE\n",
        "    word_exits = 0\n",
        "    vocab = tokenizer.index_word\n",
        "    embedded_matrix = np.zeros((5000,300))\n",
        "    print(\"Doc wordvector to %s ...\" %wordvector)\n",
        "    if wordvector == \"word2vec\":\n",
        "        model = KeyedVectors.load_word2vec_format('GoogleNews-vectors-negative300.bin', binary=True)\n",
        "    elif wordvector == \"glove\":\n",
        "        model = {}\n",
        "        with open('glove.6B.300d.txt', 'r') as f:\n",
        "            for line in f:\n",
        "                l = line.split()\n",
        "                word = l[0]\n",
        "                model[word] = np.array(l[1:]).astype(float)\n",
        "    elif wordvector == \"fasttext\":\n",
        "        model = KeyedVectors.load_word2vec_format('wiki-news-300d-1M.vec')\n",
        "\n",
        "    for word in vocab:\n",
        "        if word > 4999:\n",
        "            break\n",
        "        try:\n",
        "            embedded_matrix[word, :] = model[vocab[word]]\n",
        "            word_exits += 1\n",
        "        except KeyError:\n",
        "            if word == 0:\n",
        "                embedded_matrix[word, :] = np.zeros(300)\n",
        "            else:\n",
        "                # 0.25 is embedding SD\n",
        "                embedded_matrix[word, :] = np.random.uniform(-0.25, 0.25, 300)\n",
        "    print(\"Found %s word in embedding file\" %word_exits)\n",
        "    # YOUR CODE HERE\n",
        "    return embedded_matrix"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gKOm8aV7hg7c"
      },
      "source": [
        "2.3. Lập trình hàm `get_model()` để xây dựng kiến trúc mạng Deep Learning cho bài toán. Học viên có thể tham khảo mô hình của bài thực hành trên lớp"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0zJLJP2BdunK"
      },
      "source": [
        "def get_model(embedding=\"random\"):\n",
        "    # YOUR CODE HERE\n",
        "    input_s = Input(name='input_si', shape=(max_len,), dtype='int32')\n",
        "    if embedding == \"random\":\n",
        "        shared_embedding = Embedding(name='emb', input_dim=num_words, input_length=max_len,\n",
        "                                output_dim=embedding_dim, mask_zero=False, trainable=True)\n",
        "    else:\n",
        "        embedded_matrix = get_embedded(embedding)\n",
        "        shared_embedding = Embedding(name='emb', input_dim=num_words, input_length=max_len,\n",
        "                                     weights=[embedded_matrix],output_dim=embedding_dim, mask_zero=False, trainable=True)\n",
        "    s_embedding = shared_embedding(input_s)\n",
        "    s_embedding = Dropout(dropout)(s_embedding)\n",
        "    shared_lstm = Bidirectional(\n",
        "            lstm(hidden_dim, input_shape=(None, 500, 300),return_sequences=False, name='rnn'),\n",
        "            merge_mode='concat')\n",
        "    s_lstm = shared_lstm(s_embedding)\n",
        "    s_lstm = Dropout(dropout)(s_lstm)\n",
        "    yhat = Dense(20, activation=\"sigmoid\")(s_lstm)\n",
        "    model = Model(inputs=input_s, outputs=yhat)\n",
        "    model.compile(loss='binary_crossentropy', metrics=['accuracy'], optimizer=\"adam\")\n",
        "    # YOUR CODE HERE\n",
        "    return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sGkvn9xQ1IcK",
        "outputId": "fb799312-9738-4a87-c076-a77d5eeb8078"
      },
      "source": [
        "# YOUR CODE HERE\r\n",
        "text_clf = get_model()\r\n",
        "# YOUR CODE HERE\r\n",
        "text_clf.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"functional_7\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_si (InputLayer)        [(None, 300)]             0         \n",
            "_________________________________________________________________\n",
            "emb (Embedding)              (None, 300, 300)          1500000   \n",
            "_________________________________________________________________\n",
            "dropout_6 (Dropout)          (None, 300, 300)          0         \n",
            "_________________________________________________________________\n",
            "bidirectional_3 (Bidirection (None, 1500)              6312000   \n",
            "_________________________________________________________________\n",
            "dropout_7 (Dropout)          (None, 1500)              0         \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 20)                30020     \n",
            "=================================================================\n",
            "Total params: 7,842,020\n",
            "Trainable params: 7,842,020\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HUMHfH8v8wSV"
      },
      "source": [
        "# **Câu 3:** Huấn luyện mô hình\n",
        "\n",
        "\n",
        "\n",
        "3.1. Khởi tạo mô hình\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MFaAy8DwC3yy",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 407
        },
        "outputId": "30e70342-f4ad-4e6a-a71b-d767a2e8545a"
      },
      "source": [
        "# YOUR CODE HERE\n",
        "text_clf = get_model()\n",
        "# YOUR CODE HERE\n",
        "text_clf.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Doc wordvector to glove ...\n",
            "Found 4895 word in embedding file\n",
            "Model: \"functional_15\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_si (InputLayer)        [(None, 300)]             0         \n",
            "_________________________________________________________________\n",
            "emb (Embedding)              (None, 300, 300)          1500000   \n",
            "_________________________________________________________________\n",
            "dropout_14 (Dropout)         (None, 300, 300)          0         \n",
            "_________________________________________________________________\n",
            "bidirectional_7 (Bidirection (None, 750)               6312000   \n",
            "_________________________________________________________________\n",
            "activation_7 (Activation)    (None, 750)               0         \n",
            "_________________________________________________________________\n",
            "dropout_15 (Dropout)         (None, 750)               0         \n",
            "_________________________________________________________________\n",
            "dense_7 (Dense)              (None, 20)                15020     \n",
            "=================================================================\n",
            "Total params: 7,827,020\n",
            "Trainable params: 7,827,020\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WYRC_XjSlRtc"
      },
      "source": [
        "3.2. Huấn luyện mô hình"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6MXhRo5A1qf5",
        "outputId": "dc2b576b-46e6-40e8-e58b-d691cf4e4e87"
      },
      "source": [
        "text_clf.compile(loss='categorical_crossentropy', metrics=['accuracy'], optimizer= tf.keras.optimizers.Adam(learning_rate = learning_rate))\r\n",
        "text_clf.fit(X_train, train_one_hot, validation_split=0.2, batch_size=batch_size, epochs=11)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/11\n",
            "WARNING:tensorflow:Model was constructed with shape (None, 300) for input Tensor(\"input_si_3:0\", shape=(None, 300), dtype=int32), but it was called on an input with incompatible shape (None, 500).\n",
            "WARNING:tensorflow:Model was constructed with shape (None, 300) for input Tensor(\"input_si_3:0\", shape=(None, 300), dtype=int32), but it was called on an input with incompatible shape (None, 500).\n",
            "57/57 [==============================] - ETA: 0s - loss: 2.9714 - accuracy: 0.0835WARNING:tensorflow:Model was constructed with shape (None, 300) for input Tensor(\"input_si_3:0\", shape=(None, 300), dtype=int32), but it was called on an input with incompatible shape (None, 500).\n",
            "57/57 [==============================] - 77s 1s/step - loss: 2.9714 - accuracy: 0.0835 - val_loss: 2.9258 - val_accuracy: 0.0941\n",
            "Epoch 2/11\n",
            "57/57 [==============================] - 66s 1s/step - loss: 2.6841 - accuracy: 0.1543 - val_loss: 2.4712 - val_accuracy: 0.2311\n",
            "Epoch 3/11\n",
            "57/57 [==============================] - 68s 1s/step - loss: 2.3547 - accuracy: 0.2583 - val_loss: 2.1155 - val_accuracy: 0.2881\n",
            "Epoch 4/11\n",
            "57/57 [==============================] - 68s 1s/step - loss: 1.8840 - accuracy: 0.3853 - val_loss: 2.0199 - val_accuracy: 0.3535\n",
            "Epoch 5/11\n",
            "57/57 [==============================] - 69s 1s/step - loss: 1.4679 - accuracy: 0.5181 - val_loss: 1.6561 - val_accuracy: 0.4795\n",
            "Epoch 6/11\n",
            "57/57 [==============================] - 70s 1s/step - loss: 1.2217 - accuracy: 0.5973 - val_loss: 1.6851 - val_accuracy: 0.4759\n",
            "Epoch 7/11\n",
            "57/57 [==============================] - 70s 1s/step - loss: 1.0048 - accuracy: 0.6700 - val_loss: 1.7652 - val_accuracy: 0.4843\n",
            "Epoch 8/11\n",
            "57/57 [==============================] - 70s 1s/step - loss: 0.7696 - accuracy: 0.7528 - val_loss: 1.6624 - val_accuracy: 0.5356\n",
            "Epoch 9/11\n",
            "57/57 [==============================] - 70s 1s/step - loss: 0.6550 - accuracy: 0.7925 - val_loss: 1.7875 - val_accuracy: 0.5099\n",
            "Epoch 10/11\n",
            "57/57 [==============================] - 70s 1s/step - loss: 0.5204 - accuracy: 0.8348 - val_loss: 1.8486 - val_accuracy: 0.5170\n",
            "Epoch 11/11\n",
            "57/57 [==============================] - 70s 1s/step - loss: 0.5146 - accuracy: 0.8412 - val_loss: 1.8601 - val_accuracy: 0.5228\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7efc0bef65f8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OSgrwQJO0cT7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8986925e-666e-4438-e1f6-4a026b78f42f"
      },
      "source": [
        "text_clf.evaluate(X_test,test_one_hot)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "236/236 [==============================] - 28s 120ms/step - loss: 2.1812 - accuracy: 0.4521\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[2.1812267303466797, 0.4520711600780487]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    }
  ]
}